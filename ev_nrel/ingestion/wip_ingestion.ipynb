{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status:\n",
    "1. State machine keeps running till files for all states are fetched - AOK! \n",
    "2. Lambda is invoked in parallel by the state machine - AOK! \n",
    "\n",
    "### Todos:\n",
    "1. Needs to be put in one script\n",
    "2. lambda files: zip and python script need to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab role arn is arn:aws:iam::040284194960:role/LabRole\n",
      "S3 bucket exists\n"
     ]
    }
   ],
   "source": [
    "# Initialize the clients for S3 and DynamoDB\n",
    "from botocore.client import Config\n",
    "s3 = boto3.client('s3', region_name= \"us-east-1\",config=Config(signature_version='s3v4'))\n",
    "s3_resource = boto3.resource('s3')\n",
    "iam_client = boto3.client('iam')\n",
    "role_arn = iam_client.get_role(RoleName='LabRole')['Role']['Arn']\n",
    "print(f\"Lab role arn is {role_arn}\")\n",
    "\n",
    "# Initialize the client for Step Functions\n",
    "sfn = boto3.client('stepfunctions')\n",
    "\n",
    "# Define S3 bucket name for project\n",
    "bucket_name = 'final-project-nrel-stations'\n",
    "\n",
    "# define folder name inside s3 bucket\n",
    "folder_name = 'station-parquet-files'\n",
    "\n",
    "# Check if s3 bucket exists; if not, create \n",
    "if 'Buckets' in s3.list_buckets():\n",
    "    for bucket in s3.list_buckets()['Buckets']:\n",
    "        if bucket['Name'] == 'final-project-nrel-stations':\n",
    "            print('S3 bucket exists')\n",
    "            break\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lambda function\n",
    "def lambda_handler(event,context):\n",
    "\n",
    "    # Define start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Extract relevant attributes from the event\n",
    "    api_key = event['api_key']\n",
    "    state=event['state']\n",
    "\n",
    "    url = f\"https://developer.nrel.gov/api/alt-fuel-stations/v1.json?api_key={api_key}&state={state}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"status\": \"FAILED\",\n",
    "            \"state\": state,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "    \n",
    "    # Count the number of fuel stations returned\n",
    "    print(f\"Number of fuel stations in {state}: {data['total_results']}\")\n",
    "    \n",
    "    # Extract the list of fuel stations\n",
    "    stations = data['fuel_stations']\n",
    "    stations_df = pd.DataFrame(stations)\n",
    "\n",
    "    # Upload stations dataframe to S3 bucket as parquet with state initials\n",
    "    try:\n",
    "        stations_df.to_parquet(f\"/tmp/{state}_stations.parquet\")\n",
    "        s3.upload_file(f\"/tmp/{state}_stations.parquet\", bucket_name, f\"{folder_name}/{state}_stations.parquet\")\n",
    "        print(f'parquet file uploaded for state {state} to S3')\n",
    "        \n",
    "        # Define end time\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Construct a success response\n",
    "        return {\n",
    "            \"statusCode\": 200,\n",
    "            \"body\": json.dumps({\n",
    "                \"message\": f\"Success! Parquet file uploaded for state {state} to S3\",\n",
    "                \"processingTime\": f\"{end_time - start_time:.2f} seconds\"\n",
    "            })\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Error uploading file to S3')\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"body\": json.dumps({\n",
    "                \"message\": \"Failed to upload parquet file to S3\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fuel stations in CA: 20132\n",
      "parquet file uploaded for state CA to S3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'statusCode': 200,\n",
       " 'body': '{\"message\": \"Success! Parquet file uploaded for state CA to S3\", \"processingTime\": \"8.12 seconds\"}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing lambda locally\n",
    "api_key = 'uV8N2wWyuRXAFp1hJLIxVlHiq5pBOs1injQxbnjo'\n",
    "state = 'CA'\n",
    "event = {'api_key': api_key, 'state': state}\n",
    "lambda_handler(event, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State machine definition to invoke lambda in parallel for multiple states \n",
    "# Edited with help from Chat-GPT to include retry logic for failed states\n",
    "\n",
    "state_machine_definition = {\n",
    "  \"Comment\": \"Invoke NREL EV station function in parallel for different states\",\n",
    "  \"StartAt\": \"ParallelLambdaInvocations\",\n",
    "  \"States\": {\n",
    "    \"ParallelLambdaInvocations\": {\n",
    "      \"Type\": \"Map\",\n",
    "      \"InputPath\": \"$\",\n",
    "      \"ItemsPath\": \"$.states\",\n",
    "      \"MaxConcurrency\": 8,\n",
    "      \"Iterator\": {\n",
    "        \"StartAt\": \"InvokeLambda\",\n",
    "        \"States\": {\n",
    "          \"InvokeLambda\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:lambda:us-east-1:040284194960:function:nrel-ev-py3-9\",\n",
    "            \"End\": True\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ResultPath\": \"$.results\",\n",
    "      \"Next\": \"CheckResults\"\n",
    "    },\n",
    "    \"CheckResults\": {\n",
    "      \"Type\": \"Choice\",\n",
    "      \"Choices\": [\n",
    "        {\n",
    "          \"Variable\": \"$.results\",\n",
    "          \"IsPresent\": True,\n",
    "          \"Next\": \"RetryFailedStates\"\n",
    "        }\n",
    "      ],\n",
    "      \"Default\": \"Success\"\n",
    "    },\n",
    "    \"RetryFailedStates\": {\n",
    "      \"Type\": \"Map\",\n",
    "      \"ItemsPath\": \"$.results\",\n",
    "      \"MaxConcurrency\": 8,\n",
    "      \"Iterator\": {\n",
    "        \"StartAt\": \"InvokeFailedLambda\",\n",
    "        \"States\": {\n",
    "          \"InvokeFailedLambda\": {\n",
    "            \"Type\": \"Task\",\n",
    "            \"Resource\": \"arn:aws:lambda:us-east-1:040284194960:function:nrel-ev-py3-9\",\n",
    "            \"End\": True\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"ResultPath\": \"$.retryResults\",\n",
    "      \"Next\": \"CheckRetryResults\"\n",
    "    },\n",
    "    \"CheckRetryResults\": {\n",
    "      \"Type\": \"Choice\",\n",
    "      \"Choices\": [\n",
    "        {\n",
    "          \"Variable\": \"$.retryResults\",\n",
    "          \"IsPresent\": True,\n",
    "          \"Next\": \"RetryFailedStates\"\n",
    "        }\n",
    "      ],\n",
    "      \"Default\": \"Success\"\n",
    "    },\n",
    "    \"Success\": {\n",
    "      \"Type\": \"Succeed\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining step function (state machine) to invoke lambda concurrently for all states\n",
    "\n",
    "state_machine_definition = {\n",
    "    \"Comment\": \"Invoke NREL EV station function in parallel for different states\",\n",
    "    \"StartAt\": \"ParallelLambdaInvocations\",\n",
    "    \"States\": {\n",
    "        \"ParallelLambdaInvocations\": {\n",
    "            \"Type\": \"Map\", # Allows parallel processing for states\n",
    "            \"InputPath\": \"$\",\n",
    "            \"ItemsPath\": \"$.states\",\n",
    "            \"MaxConcurrency\": 8,\n",
    "            \"Iterator\": {\n",
    "                \"StartAt\": \"InvokeLambda\",\n",
    "                \"States\": {\n",
    "                    \"InvokeLambda\": {\n",
    "                        \"Type\": \"Task\",\n",
    "                        \"Resource\": \"arn:aws:lambda:us-east-1:040284194960:function:nrel-ev-py3-9\",\n",
    "                        \"End\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.results\", # New key in the output\n",
    "            \"Next\": \"CheckResults\" # Changed state to CheckResults\n",
    "        },\n",
    "        \"CheckResults\": {\n",
    "            \"Type\": \"Choice\",\n",
    "            \"Choices\": [\n",
    "                {\n",
    "                    \"Variable\": \"$.results[*].status\",\n",
    "                    \"StringEquals\": \"FAILED\",\n",
    "                    \"Next\": \"RetryFailedStates\"\n",
    "                }\n",
    "            ],\n",
    "            \"Default\": \"Succeess\"\n",
    "        },\n",
    "        \"RetryFailedStates\": {\n",
    "            \"Type\": \"Map\",\n",
    "            \"ItemsPath\": \"$.results[?(@.status=='FAILED')]\",\n",
    "            \"MaxConcurrency\": 8,\n",
    "            \"Iterator\": {\n",
    "                \"StartAt\": \"InvokeFailedLambda\",\n",
    "                \"States\": {\n",
    "                    \"InvokeFailedLambda\": {\n",
    "                        \"Type\": \"Task\",\n",
    "                        \"Resource\": \"arn:aws:lambda:us-east-1:040284194960:function:nrel-ev-py3-9\",\n",
    "                        \"End\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"ResultPath\": \"$.retryResults\",\n",
    "            \"Next\": \"CheckRetryResults\"\n",
    "            },\n",
    "        \"CheckRetryResults\": {\n",
    "            \"Type\": \"Choice\",\n",
    "            \"Choices\": [\n",
    "                {\n",
    "                    \"Variable\": \"$.retryResults[*].status\",\n",
    "                    \"StringEquals\": \"FAILED\",\n",
    "                    \"Next\": \"RetryFailedStates\"\n",
    "                }\n",
    "            ],\n",
    "            \"Default\": \"Success\"\n",
    "        },\n",
    "        \"Success\": {\n",
    "            \"Type\": \"Succeed\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "response = sfn.create_state_machine(\n",
    "    name='NREL_EV_Stations_State_Machine',\n",
    "    definition=json.dumps(state_machine_definition),\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "# Capture the state machine ARN for later use\n",
    "state_machine_arn = response['stateMachineArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State machine updated: arn:aws:states:us-east-1:040284194960:stateMachine:NREL_EV_Stations_State_Machine\n",
      "State machine ARN: arn:aws:states:us-east-1:040284194960:stateMachine:NREL_EV_Stations_State_Machine\n"
     ]
    }
   ],
   "source": [
    "# Check if state machine exists; if not, create. If it does, update the definition\n",
    "state_machine_arn = None\n",
    "state_machine_name = 'NREL_EV_Stations_State_Machine'\n",
    "for state_machine in sfn.list_state_machines()['stateMachines']:\n",
    "    if state_machine['name'] == state_machine_name:\n",
    "        state_machine_arn = state_machine['stateMachineArn']\n",
    "        break\n",
    "if state_machine_arn:\n",
    "    response = sfn.update_state_machine(\n",
    "        stateMachineArn=state_machine_arn,\n",
    "        definition=json.dumps(state_machine_definition)\n",
    "    )\n",
    "    print(f\"State machine updated: {state_machine_arn}\")\n",
    "else:\n",
    "    response = sfn.create_state_machine(\n",
    "        name=state_machine_name,\n",
    "        definition=json.dumps(state_machine_definition),\n",
    "        roleArn=role_arn\n",
    "    )\n",
    "    state_machine_arn = response['stateMachineArn']\n",
    "    print(f\"State machine created: {state_machine_arn}\")\n",
    "    \n",
    "print(f\"State machine ARN: {state_machine_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Executing the state machine\n",
    "# Before execution, check if files corresponding to certain states exist in S3 bucket already\n",
    "\n",
    "# Define the list of states for which we want to extract EV stations\n",
    "api_key = 'uV8N2wWyuRXAFp1hJLIxVlHiq5pBOs1injQxbnjo'\n",
    "states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "existing_files = []\n",
    "for state in states:\n",
    "    try:\n",
    "        s3_resource.Object(bucket_name, f\"{folder_name}/{state}_stations.parquet\").load()\n",
    "        existing_files.append(state)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Filter out states with existing files\n",
    "states_to_process = [state for state in states if state not in existing_files]\n",
    "\n",
    "# With the remaining states, create the input for the state machine\n",
    "execution_input = {\n",
    "    \"states\": [{\n",
    "        \"api_key\": api_key, \n",
    "        \"state\": state} for state in states_to_process]\n",
    "}\n",
    "\n",
    "# Start the execution\n",
    "execution_response = sfn.start_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    input=json.dumps(execution_input)\n",
    ")\n",
    "\n",
    "# Optionally, monitor the execution status\n",
    "execution_arn = execution_response['executionArn']\n",
    "describe_response = sfn.describe_execution(\n",
    "    executionArn=execution_arn\n",
    ")\n",
    "print(describe_response['status'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev-transit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
