{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pyarrow.parquet as pq\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab role arn is arn:aws:iam::040284194960:role/LabRole\n",
      "S3 bucket exists\n"
     ]
    }
   ],
   "source": [
    "# Initialize the clients for S3 and DynamoDB\n",
    "from botocore.client import Config\n",
    "s3 = boto3.client('s3', region_name= \"us-east-1\",config=Config(signature_version='s3v4'))\n",
    "s3_resource = boto3.resource('s3')\n",
    "iam_client = boto3.client('iam')\n",
    "role_arn = iam_client.get_role(RoleName='LabRole')['Role']['Arn']\n",
    "print(f\"Lab role arn is {role_arn}\")\n",
    "\n",
    "# Initialize the client for Step Functions\n",
    "sfn = boto3.client('stepfunctions')\n",
    "\n",
    "# Define S3 bucket name for project\n",
    "bucket_name = 'final-project-nrel-stations'\n",
    "\n",
    "# define folder name inside s3 bucket\n",
    "folder_name = 'station-parquet-files'\n",
    "\n",
    "# Check if s3 bucket exists; if not, create \n",
    "if 'Buckets' in s3.list_buckets():\n",
    "    for bucket in s3.list_buckets()['Buckets']:\n",
    "        if bucket['Name'] == 'final-project-nrel-stations':\n",
    "            print('S3 bucket exists')\n",
    "            break\n",
    "    else:\n",
    "        s3.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lambda function\n",
    "def lambda_handler(event,context):\n",
    "\n",
    "    # Define start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Extract relevant attributes from the event\n",
    "    api_key = event['api_key']\n",
    "    state=event['state']\n",
    "\n",
    "    url = f\"https://developer.nrel.gov/api/alt-fuel-stations/v1.json?api_key={api_key}&state={state}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Count the number of fuel stations returned\n",
    "    print(f\"Number of fuel stations in {state}: {data['total_results']}\")\n",
    "    \n",
    "    # Extract the list of fuel stations\n",
    "    stations = data['fuel_stations']\n",
    "    stations_df = pd.DataFrame(stations)\n",
    "\n",
    "    # Upload stations dataframe to S3 bucket as parquet with state initials\n",
    "    try:\n",
    "        stations_df.to_parquet(f\"/tmp/{state}_stations.parquet\")\n",
    "        s3.upload_file(f\"/tmp/{state}_stations.parquet\", bucket_name, f\"{folder_name}/{state}_stations.parquet\")\n",
    "        print(f'parquet file uploaded for state {state} to S3')\n",
    "        \n",
    "        # Define end time\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Construct a success response\n",
    "        return {\n",
    "            \"statusCode\": 200,\n",
    "            \"body\": json.dumps({\n",
    "                \"message\": f\"Success! Parquet file uploaded for state {state} to S3\",\n",
    "                \"processingTime\": f\"{end_time - start_time:.2f} seconds\"\n",
    "            })\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Error uploading file to S3')\n",
    "        return {\n",
    "            \"statusCode\": 500,\n",
    "            \"body\": json.dumps({\n",
    "                \"message\": \"Failed to upload parquet file to S3\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing lambda locally\n",
    "api_key = 'uV8N2wWyuRXAFp1hJLIxVlHiq5pBOs1injQxbnjo'\n",
    "state = 'IL'\n",
    "event = {'api_key': api_key, 'state': state}\n",
    "#lambda_handler(event, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining step function to invoke lambda concurrently for all states\n",
    "# Define your state machine\n",
    "state_machine_definition = {\n",
    "    \"Comment\": \"Invoke NREL EV station function in parallel for different states\",\n",
    "    \"StartAt\": \"ParallelLambdaInvocations\",\n",
    "    \"States\": {\n",
    "        \"ParallelLambdaInvocations\": {\n",
    "            \"Type\": \"Map\",\n",
    "            \"InputPath\": \"$\",\n",
    "            \"ItemsPath\": \"$.states\",\n",
    "            \"MaxConcurrency\": 8,\n",
    "            \"Iterator\": {\n",
    "                \"StartAt\": \"InvokeLambda\",\n",
    "                \"States\": {\n",
    "                    \"InvokeLambda\": {\n",
    "                        \"Type\": \"Task\",\n",
    "                        \"Resource\": \"arn:aws:lambda:us-east-1:040284194960:function:nrel-ev-py3-9\",\n",
    "                        \"End\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"End\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create or update the state machine\n",
    "response = sfn.create_state_machine(\n",
    "    name='NREL_EV_Stations_State_Machine',\n",
    "    definition=json.dumps(state_machine_definition),\n",
    "    roleArn=role_arn\n",
    ")\n",
    "\n",
    "# Capture the state machine ARN for later use\n",
    "state_machine_arn = response['stateMachineArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State machine ARN: arn:aws:states:us-east-1:040284194960:stateMachine:NREL_EV_Stations_State_Machine\n"
     ]
    }
   ],
   "source": [
    "# print the state machine ARN\n",
    "print(f\"State machine ARN: {state_machine_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of states for which we want to extract EV stations\n",
    "states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "execution_input = {\n",
    "    \"states\": [\n",
    "        {\"api_key\": api_key, \"state\": state}\n",
    "        for state in states\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Start execution\n",
    "execution_response = sfn.start_execution(\n",
    "    stateMachineArn=state_machine_arn,\n",
    "    input=json.dumps(execution_input)\n",
    ")\n",
    "\n",
    "# Optionally, monitor the execution status\n",
    "execution_arn = execution_response['executionArn']\n",
    "describe_response = sfn.describe_execution(\n",
    "    executionArn=execution_arn\n",
    ")\n",
    "print(describe_response['status'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ev-transit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
